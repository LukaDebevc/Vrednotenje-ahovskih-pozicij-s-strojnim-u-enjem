{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7845d8d-40ed-4949-9ab4-23641d408a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import chess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from chess import Piece\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import MultiplicativeLR\n",
    "\n",
    "\n",
    "def encode_board(board):\n",
    "    encoded = torch.zeros(2, 6, 8, 8)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            color = int(piece.color)\n",
    "            piece_type = piece.piece_type - 1\n",
    "            rank = square // 8\n",
    "            file = square % 8\n",
    "            encoded[color, piece_type, rank, file] = 1\n",
    "    return encoded.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6d4e95-1601-466e-a911-98d43f7aa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.train = True\n",
    "        self.filtered = True\n",
    "        self.data_filtered = []\n",
    "        self.data_unfiltered = []\n",
    "        self.process_files(folder_path)\n",
    "        random.shuffle(self.data_filtered)\n",
    "        random.shuffle(self.data_unfiltered)\n",
    "        self.train_data_filtered = self.data_filtered[:int(len(self.data_filtered)*0.8)]\n",
    "        self.test_data_filtered = self.data_filtered[int(len(self.data_filtered)*0.8):]\n",
    "        self.train_data_unfiltered = self.data_unfiltered[:int(len(self.data_unfiltered)*0.8)]\n",
    "        self.test_data_unfiltered = self.data_unfiltered[int(len(self.data_unfiltered)*0.8):]\n",
    "\n",
    "    def process_files(self, folder_path):\n",
    "        move_pattern = re.compile(r'\\b([NBRQK]?[a-h]?[1-8]?x?[a-h][1-8](=[NBRQ])?|O-O(?:-O)?)')\n",
    "        for i, filename in enumerate(os.listdir(folder_path)):\n",
    "            if i % 5000 == 0: print(i)\n",
    "            if i == 50_000:\n",
    "                break\n",
    "            if filename.endswith('.pgn'):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                with open(file_path, 'r') as pgn_file:\n",
    "                    content = pgn_file.read()\n",
    "                    moves = move_pattern.findall(content)\n",
    "                    result_match = re.search(r'\\s(1-0|0-1|1/2-1/2)\\s', content)\n",
    "                    result = result_match.group(1) if result_match else None\n",
    "                    if not moves or not result:\n",
    "                        continue\n",
    "                    board = chess.Board()\n",
    "                    valid_moves = []\n",
    "                    moves = [i for i, _ in moves]\n",
    "                    for move in moves:\n",
    "                        try:\n",
    "                            board.push_san(move)\n",
    "                            valid_moves.append(move)\n",
    "                        except ValueError:\n",
    "                            break\n",
    "                    if valid_moves:\n",
    "                        num_samples = 1 + len(valid_moves) // 5\n",
    "                        sample_indices = random.sample(range(len(valid_moves)), num_samples)\n",
    "                        for sample_index in sample_indices:\n",
    "                            board = chess.Board()\n",
    "                            for i, move in enumerate(valid_moves):\n",
    "                                if i == sample_index:\n",
    "                                    break\n",
    "                                board.push_san(move)\n",
    "                            board_state = encode_board(board)\n",
    "                            next_move = valid_moves[sample_index] if sample_index < len(valid_moves) else None\n",
    "                            next_move1 = valid_moves[sample_index + 1] if sample_index + 1 < len(valid_moves) else None\n",
    "                            next_move2 = valid_moves[sample_index + 2] if sample_index + 2 < len(valid_moves) else None\n",
    "                            is_capture = (((\"x\" in next_move) if next_move else 0) or\n",
    "                                          ((\"x\" in next_move) if next_move else 0) or\n",
    "                                            ((\"x\" in next_move2) if next_move2 else 0))\n",
    "                            if result == '1-0':\n",
    "                                y = 1.0\n",
    "                            elif result == '0-1':\n",
    "                                y = 0.0\n",
    "                            else:\n",
    "                                y = 0.5\n",
    "                            if not is_capture:\n",
    "                                self.data_filtered.append((board_state.cuda(), torch.tensor(y, dtype=torch.float32).cuda()))\n",
    "                            self.data_unfiltered.append((board_state.cuda(), torch.tensor(y, dtype=torch.float32).cuda()))\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train and self.filtered:\n",
    "            return len(self.train_data_filtered)\n",
    "        elif self.train and (not self.filtered):\n",
    "            return len(self.train_data_unfiltered)\n",
    "        elif (not self.train) and self.filtered:\n",
    "            return len(self.test_data_filtered)\n",
    "        else:\n",
    "            return len(self.test_data_unfiltered)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train and self.filtered:\n",
    "            return (self.train_data_filtered[idx][0], self.train_data_filtered[idx][1])\n",
    "        elif self.train and (not self.filtered):\n",
    "            return (self.train_data_unfiltered[idx][0], self.train_data_unfiltered[idx][1])\n",
    "        elif (not self.train) and self.filtered:\n",
    "            return (self.test_data_filtered[idx][0], self.test_data_filtered[idx][1])\n",
    "        else:\n",
    "            return (self.test_data_unfiltered[idx][0], self.test_data_unfiltered[idx][1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e2046f-3192-437a-a57f-d8c8a490c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSQT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PSQT, self).__init__()\n",
    "        self.psqt1 = nn.Linear(768, 32, bias=False) # lahko posedemo, pospeÅ¡i konvergenco\n",
    "        torch.nn.init.constant_(self.psqt1.weight, 0)\n",
    "        self.psqt2 = nn.Linear(32, 1, bias=False) # posamezne vrednosti lahko pridobimo z self.psqt2(self.psqt1(x)), kjer je x one hot encoding\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.psqt2(self.psqt1(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bade7b2f-4069-4222-ac23-7d95875540ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pieces(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pieces, self).__init__()\n",
    "        self.pieces = nn.Parameter(torch.zeros(6))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2, 6, 64)\n",
    "        x = x.sum(dim=3)\n",
    "        x = x[:, 1, :] - x[:, 0, :]\n",
    "        x = (torch.sum(x * self.pieces, dim=1, keepdim=True))\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc3c942-7fc0-4156-a900-537eb8ee7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, scheduler, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs\n",
    "            labels = labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            try:\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a26eb3-ff36-48ea-996f-1d779414e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset, experiment):\n",
    "    print(\"train\")\n",
    "    model, filtered, criterion, optimizer, scheduler, epochs = experiment\n",
    "    if filtered == \"filtered\":\n",
    "        dataset.filtered = True\n",
    "    else:\n",
    "        dataset.filtered = False\n",
    "    dataset.train = True\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=2 ** 5, shuffle=True)\n",
    "    train_model(model, train_dataloader, criterion, optimizer, scheduler, num_epochs=epochs)\n",
    "\n",
    "    print(\"test\")\n",
    "    dataset.train = False\n",
    "    train_model(model, train_dataloader, criterion, optim.Adam(model.parameters(), lr=0), scheduler, num_epochs=1)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54d9aff-149d-4a78-8420-7886f9cc0ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "\n",
      "Running experiment: (Pieces(\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'unfiltered', BCELoss(), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.MultiplicativeLR object at 0x7887ec5875b0>, 31)\n",
      "train\n",
      "Epoch 1, Loss: 0.6237303920685981\n",
      "Epoch 11, Loss: 0.6230529361803224\n",
      "Epoch 21, Loss: 0.6230176040849421\n",
      "Epoch 31, Loss: 0.6230124386297317\n",
      "test\n",
      "Epoch 1, Loss: 0.6228334694511597\n",
      "parameters\n",
      "[Parameter containing:\n",
      "tensor([0.4715, 0.9801, 1.0760, 1.6307, 2.9666, 0.0000], device='cuda:0',\n",
      "       requires_grad=True)]\n",
      "\n",
      "Running experiment: (Pieces(\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'filtered', BCELoss(), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.MultiplicativeLR object at 0x7887e3fe20e0>, 31)\n",
      "train\n",
      "Epoch 1, Loss: 0.5921549316595666\n",
      "Epoch 11, Loss: 0.5908678574135925\n",
      "Epoch 21, Loss: 0.5908293441957807\n",
      "Epoch 31, Loss: 0.5908273163242574\n",
      "test\n",
      "Epoch 1, Loss: 0.5906927571115907\n",
      "parameters\n",
      "[Parameter containing:\n",
      "tensor([0.5892, 1.6083, 1.7127, 2.5516, 4.8701, 0.0000], device='cuda:0',\n",
      "       requires_grad=True)]\n",
      "\n",
      "Running experiment: (Pieces(\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'unfiltered', MSELoss(), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.MultiplicativeLR object at 0x7887e3e16a70>, 31)\n",
      "train\n",
      "Epoch 1, Loss: 0.11748068121790349\n",
      "Epoch 11, Loss: 0.11720243107907279\n",
      "Epoch 21, Loss: 0.1171845169255648\n",
      "Epoch 31, Loss: 0.11718158306846355\n",
      "test\n",
      "Epoch 1, Loss: 0.11680880905969651\n",
      "parameters\n",
      "[Parameter containing:\n",
      "tensor([0.4684, 1.0588, 1.1561, 1.7639, 3.4830, 0.0000], device='cuda:0',\n",
      "       requires_grad=True)]\n",
      "\n",
      "Running experiment: (Pieces(\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'filtered', MSELoss(), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.MultiplicativeLR object at 0x7887e3e16bf0>, 31)\n",
      "train\n",
      "Epoch 1, Loss: 0.10477391903655446\n",
      "Epoch 11, Loss: 0.10421627348255993\n",
      "Epoch 21, Loss: 0.104201907271584\n",
      "Epoch 31, Loss: 0.10420036650656823\n",
      "test\n",
      "Epoch 1, Loss: 0.10431544671266092\n",
      "parameters\n",
      "[Parameter containing:\n",
      "tensor([0.5918, 1.7272, 1.8364, 2.7325, 5.3511, 0.0000], device='cuda:0',\n",
      "       requires_grad=True)]\n",
      "\n",
      "Running experiment: (Pieces(\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'unfiltered', L1Loss(), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.MultiplicativeLR object at 0x7887e3e16d70>, 31)\n",
      "train\n",
      "Epoch 1, Loss: 0.26039572929873883\n",
      "Epoch 11, Loss: 0.2596634650346267\n",
      "Epoch 21, Loss: 0.2596226321378331\n",
      "Epoch 31, Loss: 0.2596201208315946\n",
      "test\n",
      "Epoch 1, Loss: 0.25890870192152765\n",
      "parameters\n",
      "[Parameter containing:\n",
      "tensor([0.4673, 1.8689, 1.8690, 2.8036, 5.6071, 0.0000], device='cuda:0',\n",
      "       requires_grad=True)]\n",
      "\n",
      "Running experiment: (Pieces(\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'filtered', L1Loss(), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.MultiplicativeLR object at 0x7887e3e16ef0>, 31)\n",
      "train\n",
      "Epoch 1, Loss: 0.2399113468839098\n",
      "Epoch 11, Loss: 0.238580709477124\n",
      "Epoch 21, Loss: 0.23853778606413997\n",
      "Epoch 31, Loss: 0.23853637233206668\n",
      "test\n",
      "Epoch 1, Loss: 0.23835267611515912\n",
      "parameters\n",
      "[Parameter containing:\n",
      "tensor([0.6195, 2.4780, 2.4780, 3.7169, 7.4339, 0.0000], device='cuda:0',\n",
      "       requires_grad=True)]\n",
      "\n",
      "Running experiment: (PSQT(\n",
      "  (psqt1): Linear(in_features=768, out_features=32, bias=False)\n",
      "  (psqt2): Linear(in_features=32, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'unfiltered', MSELoss(), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.MultiplicativeLR object at 0x7887e3e170a0>, 31)\n",
      "train\n",
      "Epoch 1, Loss: 0.12474389344260897\n",
      "Epoch 11, Loss: 0.11320079082205967\n",
      "Epoch 21, Loss: 0.11256755573917417\n",
      "Epoch 31, Loss: 0.11248808890329957\n",
      "test\n",
      "Epoch 1, Loss: 0.11237556783784171\n",
      "parameters\n",
      "tensor([[-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [0.9928],\n",
      "        [1.0870],\n",
      "        [0.9749],\n",
      "        [1.0169],\n",
      "        [0.9210],\n",
      "        [0.8709],\n",
      "        [0.9182],\n",
      "        [0.9831],\n",
      "        [0.7043],\n",
      "        [0.6748],\n",
      "        [0.6540],\n",
      "        [0.7090],\n",
      "        [0.7005],\n",
      "        [0.6174],\n",
      "        [0.5423],\n",
      "        [0.5633],\n",
      "        [0.5283],\n",
      "        [0.5002],\n",
      "        [0.4225],\n",
      "        [0.4376],\n",
      "        [0.5315],\n",
      "        [0.5583],\n",
      "        [0.5217],\n",
      "        [0.4469],\n",
      "        [0.4154],\n",
      "        [0.4729],\n",
      "        [0.4365],\n",
      "        [0.4668],\n",
      "        [0.4504],\n",
      "        [0.4431],\n",
      "        [0.4736],\n",
      "        [0.4179],\n",
      "        [0.4181],\n",
      "        [0.4948],\n",
      "        [0.4121],\n",
      "        [0.4382],\n",
      "        [0.4494],\n",
      "        [0.4253],\n",
      "        [0.5071],\n",
      "        [0.4198],\n",
      "        [0.4237],\n",
      "        [0.4778],\n",
      "        [0.3604],\n",
      "        [0.3534],\n",
      "        [0.4016],\n",
      "        [0.5086],\n",
      "        [0.5378],\n",
      "        [0.4209],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000]], device='cuda:0', grad_fn=<NegBackward0>)\n",
      "\n",
      "Running experiment: (PSQT(\n",
      "  (psqt1): Linear(in_features=768, out_features=32, bias=False)\n",
      "  (psqt2): Linear(in_features=32, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'filtered', MSELoss(), Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.01\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      "), <torch.optim.lr_scheduler.MultiplicativeLR object at 0x7887e3e17280>, 31)\n",
      "train\n",
      "Epoch 1, Loss: 0.1157042231250365\n",
      "Epoch 11, Loss: 0.10032635456935994\n",
      "Epoch 21, Loss: 0.09948705949546459\n",
      "Epoch 31, Loss: 0.0993711706471248\n",
      "test\n",
      "Epoch 1, Loss: 0.09962228766859196\n",
      "parameters\n",
      "tensor([[-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [1.1994],\n",
      "        [1.3723],\n",
      "        [1.2668],\n",
      "        [1.2685],\n",
      "        [1.2423],\n",
      "        [1.1246],\n",
      "        [1.1577],\n",
      "        [1.2344],\n",
      "        [0.8673],\n",
      "        [0.8664],\n",
      "        [0.8788],\n",
      "        [0.8996],\n",
      "        [0.9063],\n",
      "        [0.8338],\n",
      "        [0.7170],\n",
      "        [0.7373],\n",
      "        [0.6593],\n",
      "        [0.6304],\n",
      "        [0.5348],\n",
      "        [0.5891],\n",
      "        [0.6485],\n",
      "        [0.6937],\n",
      "        [0.6739],\n",
      "        [0.5914],\n",
      "        [0.5295],\n",
      "        [0.5979],\n",
      "        [0.5527],\n",
      "        [0.5998],\n",
      "        [0.5871],\n",
      "        [0.5727],\n",
      "        [0.6125],\n",
      "        [0.5402],\n",
      "        [0.5253],\n",
      "        [0.6274],\n",
      "        [0.5306],\n",
      "        [0.5700],\n",
      "        [0.5668],\n",
      "        [0.5654],\n",
      "        [0.6460],\n",
      "        [0.5333],\n",
      "        [0.5221],\n",
      "        [0.5857],\n",
      "        [0.4832],\n",
      "        [0.4973],\n",
      "        [0.5218],\n",
      "        [0.6506],\n",
      "        [0.6769],\n",
      "        [0.5306],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000],\n",
      "        [-0.0000]], device='cuda:0', grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'pgns-run1-test80-20220404-1254'\n",
    "dataset = ChessDataset(folder_path)\n",
    "\n",
    "experiments = [\n",
    "    (model := Pieces().cuda(), \"unfiltered\", nn.BCELoss(), optimizer := optim.Adam(model.parameters(), lr=0.01), MultiplicativeLR(optimizer, lr_lambda=lambda x: 0.8), 31),\n",
    "    (model := Pieces().cuda(), \"filtered\", nn.BCELoss(), optimizer := optim.Adam(model.parameters(), lr=0.01), MultiplicativeLR(optimizer, lr_lambda=lambda x: 0.8), 31),\n",
    "    (model := Pieces().cuda(), \"unfiltered\", nn.MSELoss(), optimizer := optim.Adam(model.parameters(), lr=0.01), MultiplicativeLR(optimizer, lr_lambda=lambda x: 0.8), 31),\n",
    "    (model := Pieces().cuda(), \"filtered\", nn.MSELoss(), optimizer := optim.Adam(model.parameters(), lr=0.01), MultiplicativeLR(optimizer, lr_lambda=lambda x: 0.8), 31),\n",
    "    (model := Pieces().cuda(), \"unfiltered\", nn.L1Loss(), optimizer := optim.Adam(model.parameters(), lr=0.01), MultiplicativeLR(optimizer, lr_lambda=lambda x: 0.8), 31),\n",
    "    (model := Pieces().cuda(), \"filtered\", nn.L1Loss(), optimizer := optim.Adam(model.parameters(), lr=0.01), MultiplicativeLR(optimizer, lr_lambda=lambda x: 0.8), 31),\n",
    "\n",
    "    (model := PSQT().cuda(), \"unfiltered\", nn.MSELoss(), optimizer := optim.Adam(model.parameters(), lr=0.01), MultiplicativeLR(optimizer, lr_lambda=lambda x: 0.8), 31),\n",
    "    (model := PSQT().cuda(), \"filtered\", nn.MSELoss(), optimizer := optim.Adam(model.parameters(), lr=0.01), MultiplicativeLR(optimizer, lr_lambda=lambda x: 0.8), 31),\n",
    "]\n",
    "\n",
    "for i in experiments:\n",
    "    print(f\"\\nRunning experiment: {i}\")\n",
    "    model = run_experiment(dataset, i)\n",
    "    print(\"parameters\")\n",
    "    if type(model) == Pieces:\n",
    "        print(list(model.parameters())[:5])\n",
    "    else:\n",
    "        print(-model.psqt2(model.psqt1(torch.Tensor([[i == j for i in range(768)] for j in range(64)]).cuda())))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecce9e-cee4-401b-9e2d-0cd85934d433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
